{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aae422b-57ec-4087-b5cc-a2f6d97d14f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import analyzer, connections, Index, Document, Text, Search\n",
    "from elasticsearch.helpers import bulk\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f164e7ae-20df-4d25-9d00-be555f1488ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections.create_connection(hosts=\"http://192.168.0.28:9200\", verify_certs=False)  # Running on separate machine on local-network due to RAM constraints\n",
    "es = Elasticsearch([\"http://192.168.0.28:9200\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d4f82-5a33-417f-93c9-10a56291fda3",
   "metadata": {},
   "source": [
    "## Zadanie 1\n",
    "\n",
    "*Use the FIQA-PL dataset that was used in lab 1 and lab lab 2 (so we need the passages, the questions and their relations).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff1aa7b-f503-46e5-9e0e-8b26b780f289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkafara/studies/9_term/pjn/repo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets as ds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dff686d-b769-4512-986b-a1c4585232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "ds_name = \"clarin-knext/fiqa-pl\"\n",
    "res_ds_name = \"clarin-knext/fiqa-pl-qrels\"\n",
    "\n",
    "queries_df = ds.load_dataset(ds_name, \"queries\")[\"queries\"].to_pandas()\n",
    "corpus_df = ds.load_dataset(ds_name, \"corpus\")[\"corpus\"].to_pandas()\n",
    "response_df = ds.load_dataset(res_ds_name)\n",
    "\n",
    "response_train_df = response_df['train'].to_pandas()\n",
    "response_validation_df = response_df['validation'].to_pandas()\n",
    "response_test_df = response_df['test'].to_pandas()\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6377ef18-1783-405a-817b-2bf5a4e459f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Rozpoczęcie nowego biznesu online</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   0        Co jest uważane za wydatek służbowy w podróży ...\n",
       "1   4        Wydatki służbowe - ubezpieczenie samochodu pod...\n",
       "2   5                        Rozpoczęcie nowego biznesu online"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee260be-743f-4c3d-be4e-4cb36ecb2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_df._id = queries_df._id.astype(int)\n",
    "corpus_df._id = corpus_df._id.astype(int)\n",
    "# response_train_df._id = response_train_df._id.astype(int)\n",
    "# response_validation_df._id = response_validation_df._id.astype(int)\n",
    "# response_test_df._id = response_test_df._id.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0debf25d-180a-47f8-9af6-6a4f974182c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _id title                                               text\n",
       "0    3        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1   31        Tak więc nic nie zapobiega fałszywym ocenom po...\n",
       "2   56        Nigdy nie możesz korzystać z FSA dla indywidua..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c979155b-e08f-47c4-90b7-0b42b26eba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18850</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>196463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>69306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         0      18850      1\n",
       "1         4     196463      1\n",
       "2         5      69306      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b38394-065d-4a6e-bb0f-b3bc5b577d38",
   "metadata": {},
   "source": [
    "## Zadania 2, 3\n",
    "\n",
    "Create a dataset of positive and negative sentence pairs. In each pair the first element is a question and the second element is a passage. Use the relations to mark the positive pairs (i.e. pairs where the question is answered by the passage). Use your own strategy to mark negative pairs (i.e. you can draw the negative examples, but there are better strategies to define the negative examples). The number of negative examples should be much larger than the number of positive examples.\n",
    "\n",
    "\n",
    "The dataset from point 2 should be split into training, evaluation and testing subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0741d23-4a4b-4211-b0cc-0feb5ba9ded6",
   "metadata": {},
   "source": [
    "Stworzenie pozytywnych par jest proste - korzystamy z danych które mamy w `reponse_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89e629c-df07-4066-9ca0-bc3240af6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_positive_pairs_from_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for index, row in df.iterrows():\n",
    "        question = queries_df.loc[queries_df._id == row['query-id']].iloc[0]['text']\n",
    "        positive_answer = corpus_df.loc[corpus_df._id == row['corpus-id']].iloc[0]['text']\n",
    "        questions.append(question)\n",
    "        answers.append(positive_answer)\n",
    "    return pd.DataFrame({\n",
    "        'query': questions,\n",
    "        'answer': answers\n",
    "    })\n",
    "\n",
    "pairs_positive_train_df = create_positive_pairs_from_df(response_train_df)\n",
    "pairs_positive_validation_df = create_positive_pairs_from_df(response_validation_df)\n",
    "pairs_positive_test_df = create_positive_pairs_from_df(response_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a95476-041a-4165-8eb9-c1565b484973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>Wytyczne IRS dotyczące tematu. Ogólnie rzecz b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>Co do zasady musisz wybrać pomiędzy odliczenie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "1  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "\n",
       "                                              answer  \n",
       "0  Wytyczne IRS dotyczące tematu. Ogólnie rzecz b...  \n",
       "1  Co do zasady musisz wybrać pomiędzy odliczenie...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_positive_train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6365f3-869e-4df9-8640-faa3585bdc72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14166, 2), (1706, 2), (1238, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_positive_train_df.shape, pairs_positive_test_df.shape, pairs_positive_validation_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835e687-2a76-493e-bdf2-4ac9bda9cd00",
   "metadata": {},
   "source": [
    "Idąc za sugestią z zajęć, pary negatywne wygeneruję jako \"złe odpowiedzi\" zwrócone przez ES'a -- albo ustawię próg na score, albo \n",
    "będę pytał o np. 20 wyników i wezmę 5 najgorszych. Jeszcze zobaczę jak to wyjdzie w praniu.\n",
    "\n",
    "Najpierw wgrajmy dane do ES'a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761d047b-6d79-4c22-9de2-083c81118cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_analyzer = analyzer('basic_analyzer', tokenizer='standard', filter=['lowercase', 'morfologik_stem', 'lowercase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "016a2f9f-81b6-4f6e-a7d9-a39c8a569d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(Document):\n",
    "    body = Text(analyzer=basic_analyzer)\n",
    "\n",
    "    class Index:\n",
    "        name = \"corpus\"\n",
    "\n",
    "Article.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67bb3339-4b3a-4197-b2ce-08a25b3cd2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles = []\n",
    "# for _, row in corpus_df.iterrows():\n",
    "#     article = Article(meta={'id': row._id}, body=row.text).to_dict(include_meta=True)\n",
    "#     articles.append(article)\n",
    "\n",
    "# bulk(es, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16366062-2d28-4a77-8dfb-23a46cb8ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "def body_for_query(query: str) -> Any:\n",
    "    return {\"query\": {\"match\": {\"body\": {\"query\": query}}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018474f-41ba-4057-97a0-544756b610d3",
   "metadata": {},
   "source": [
    "Zobaczmy czy to działa na przykładowym query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4cbbae-30e5-4b68-91a2-825ce6835f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Co jest uważane za wydatek służbowy w podróży służbowej?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = pairs_positive_train_df.iloc[0]['query']\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed369add-44d2-4ba3-89c2-3132052d83e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Dobrałem tą wartość dla przykładowego query tak, żeby faktycznie zwrócone teksty nie zawierały informacji które chociaż częściowo\n",
    "# odpowiadają na pytanie. Ciągle jest to wybór mocno arbitralny i może zdarzyć się tak, że to nie do końca będą negatywy - a jedynie\n",
    "# złej jakości pozytywy.\n",
    "result_count_upper_limit = 1000\n",
    "\n",
    "result = es.search(index='corpus', body=body_for_query(query), size=result_count_upper_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c879b11-0e23-415a-bbc5-1094254fff46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.8649077, 6.862724, 6.859345, 6.8590593, 6.858466]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda hit: hit['_score'], result.body['hits']['hits'][-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9c834a-f6c3-456c-818a-a9b3750ce473",
   "metadata": {},
   "source": [
    "Powiedzmy, że score poniżej 7 daje już satysfakcjonująco złe odpowiedzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc127a80-74f9-4749-b5bf-b75f12af2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_upper_bound = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e0224-2163-40be-b643-06bfafc35452",
   "metadata": {},
   "source": [
    "Poniżej trochę kombinuję z batchowaniem requestów, bo ESa mam postawionego na osobnej maszynie z powodu \"ramożerności\" ESa,\n",
    "a bez batchowania to potrafi się liczyć & przesyłać długo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aaae565-3b14-40ae-9448-e31197e4e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from elasticsearch_dsl.query import Query\n",
    "from elasticsearch_dsl import MultiSearch, Search\n",
    "\n",
    "def take_from_generator(generator, n):\n",
    "    while True:\n",
    "        batch = []\n",
    "        i = 0\n",
    "        while i < n:\n",
    "            try:\n",
    "                elem = next(generator)\n",
    "                batch.append(elem)\n",
    "                i += 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "        else:\n",
    "            break\n",
    "\n",
    "def create_negative_pairs_from_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    all_query_texts = []\n",
    "    neg_answers = []\n",
    "    batch_size = 256\n",
    "    with tqdm(total=df.shape[0] // batch_size) as pbar:\n",
    "        for row_batch in take_from_generator(df.iterrows(), batch_size):\n",
    "            # multiquery = MultiSearch(index='corpus', using=es)\n",
    "            queries = (queries_df.loc[queries_df._id == row_tuple[1]['query-id']].iloc[0]['text'] for row_tuple in row_batch)\n",
    "            es_queries = (body_for_query(query) for query in queries)\n",
    "    \n",
    "            query_texts = []\n",
    "            searches = []\n",
    "            for es_query in es_queries:\n",
    "                searches.append({\"index\": \"corpus\"})\n",
    "                searches.append(es_query)\n",
    "                query_texts.append(es_query['query']['match']['body']['query'])\n",
    "    \n",
    "            responses = es.msearch(index='corpus', body=searches)\n",
    "            \n",
    "            for text, response in zip(query_texts, responses['responses']):\n",
    "                last = [ans['_source']['body'] for ans in response['hits']['hits'] if ans['_score'] < score_upper_bound]\n",
    "                if len(last) > 5:\n",
    "                    last = last[-5:]\n",
    "                elif len(last) == 0:\n",
    "                    last = [ans['_source']['body'] for ans in response['hits']['hits'][-5:]]\n",
    "    \n",
    "                for ans in last:\n",
    "                    all_query_texts.append(text)\n",
    "                    neg_answers.append(ans)\n",
    "            pbar.update(1)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'query': all_query_texts,\n",
    "        'answer': neg_answers\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a58fcdb-c00e-4d1d-b2c8-1d41d34d79f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:33,  1.65it/s]                                                                                                                                                                                 \n"
     ]
    }
   ],
   "source": [
    "pairs_negative_train_df = create_negative_pairs_from_df(response_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b776934d-2ec9-4413-9730-ebf2dd30903f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.40it/s]                                                                                                                                                                                  \n",
      "7it [00:04,  1.67it/s]                                                                                                                                                                                  \n"
     ]
    }
   ],
   "source": [
    "pairs_negative_validation_df = create_negative_pairs_from_df(response_validation_df)\n",
    "pairs_negative_test_df = create_negative_pairs_from_df(response_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "028ed463-b130-479e-9fcd-fab087bae0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>Witamy na Carrental.com, oferujemy naszym klie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>&gt;I wciąż wystarczające zapotrzebowanie na zape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>„To, co robią, jest złe. IRS i państwo mogą ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>„Typowe dla dużych firm. Moja firma nie ogłasz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>Nie mówisz, w jakim kraju mieszkasz. Jeśli są ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>Nie ma prawa, które wymaga posiadania oddzieln...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>„Zwroty wydatków służbowych na ogół nie podleg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>W porządku, IRS Publikacja 463: Podróże, rozry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>Zapoznałem się z przykładami w publikacji 463 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "      <td>Z wyjątkiem tego, że ubezpieczenie większości ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "1  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "2  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "3  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "4  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "5  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "6  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "7  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "8  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "9  Wydatki służbowe - ubezpieczenie samochodu pod...   \n",
       "\n",
       "                                              answer  \n",
       "0  Witamy na Carrental.com, oferujemy naszym klie...  \n",
       "1  >I wciąż wystarczające zapotrzebowanie na zape...  \n",
       "2  „To, co robią, jest złe. IRS i państwo mogą ni...  \n",
       "3  „Typowe dla dużych firm. Moja firma nie ogłasz...  \n",
       "4  Nie mówisz, w jakim kraju mieszkasz. Jeśli są ...  \n",
       "5  Nie ma prawa, które wymaga posiadania oddzieln...  \n",
       "6  „Zwroty wydatków służbowych na ogół nie podleg...  \n",
       "7  W porządku, IRS Publikacja 463: Podróże, rozry...  \n",
       "8  Zapoznałem się z przykładami w publikacji 463 ...  \n",
       "9  Z wyjątkiem tego, że ubezpieczenie większości ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_negative_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0a85e1b-a3ef-464b-9b20-fa198ccb297b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70814</th>\n",
       "      <td>Czy strata kapitałowa w tradycyjnej IRA i Roth...</td>\n",
       "      <td>1) Dlaczego nie mógłbym wpłacać składek na kon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70815</th>\n",
       "      <td>Czy strata kapitałowa w tradycyjnej IRA i Roth...</td>\n",
       "      <td>Tak, możesz wpłacać niepodlegające odliczeniu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70816</th>\n",
       "      <td>Czy strata kapitałowa w tradycyjnej IRA i Roth...</td>\n",
       "      <td>Rollover IRA to tradycyjna IRA. Twoje składki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70817</th>\n",
       "      <td>Czy strata kapitałowa w tradycyjnej IRA i Roth...</td>\n",
       "      <td>„W dzisiejszych czasach, jak wspomniał JoeTaxp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70818</th>\n",
       "      <td>Czy strata kapitałowa w tradycyjnej IRA i Roth...</td>\n",
       "      <td>Musisz złożyć wniosek jako żonaty/zamężna za r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70819</th>\n",
       "      <td>Sprzedaż akcji w celu zrekompensowania innych ...</td>\n",
       "      <td>\"Po raz kolejny udzielam mądrej rady - \"\"Nie p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70820</th>\n",
       "      <td>Sprzedaż akcji w celu zrekompensowania innych ...</td>\n",
       "      <td>Sprzedaż akcji tworzy zysk kapitałowy. Można t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70821</th>\n",
       "      <td>Sprzedaż akcji w celu zrekompensowania innych ...</td>\n",
       "      <td>Obawiam się, że nie dostaniesz tu żadnych dobr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70822</th>\n",
       "      <td>Sprzedaż akcji w celu zrekompensowania innych ...</td>\n",
       "      <td>Z paragrafu 1091 IRS. Strata z tytułu sprzedaż...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70823</th>\n",
       "      <td>Sprzedaż akcji w celu zrekompensowania innych ...</td>\n",
       "      <td>Nie jesteś osobą ani podmiotem, przeciwko któr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   query  \\\n",
       "70814  Czy strata kapitałowa w tradycyjnej IRA i Roth...   \n",
       "70815  Czy strata kapitałowa w tradycyjnej IRA i Roth...   \n",
       "70816  Czy strata kapitałowa w tradycyjnej IRA i Roth...   \n",
       "70817  Czy strata kapitałowa w tradycyjnej IRA i Roth...   \n",
       "70818  Czy strata kapitałowa w tradycyjnej IRA i Roth...   \n",
       "70819  Sprzedaż akcji w celu zrekompensowania innych ...   \n",
       "70820  Sprzedaż akcji w celu zrekompensowania innych ...   \n",
       "70821  Sprzedaż akcji w celu zrekompensowania innych ...   \n",
       "70822  Sprzedaż akcji w celu zrekompensowania innych ...   \n",
       "70823  Sprzedaż akcji w celu zrekompensowania innych ...   \n",
       "\n",
       "                                                  answer  \n",
       "70814  1) Dlaczego nie mógłbym wpłacać składek na kon...  \n",
       "70815  Tak, możesz wpłacać niepodlegające odliczeniu ...  \n",
       "70816  Rollover IRA to tradycyjna IRA. Twoje składki ...  \n",
       "70817  „W dzisiejszych czasach, jak wspomniał JoeTaxp...  \n",
       "70818  Musisz złożyć wniosek jako żonaty/zamężna za r...  \n",
       "70819  \"Po raz kolejny udzielam mądrej rady - \"\"Nie p...  \n",
       "70820  Sprzedaż akcji tworzy zysk kapitałowy. Można t...  \n",
       "70821  Obawiam się, że nie dostaniesz tu żadnych dobr...  \n",
       "70822  Z paragrafu 1091 IRS. Strata z tytułu sprzedaż...  \n",
       "70823  Nie jesteś osobą ani podmiotem, przeciwko któr...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_negative_train_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0538c9-8fca-4cc9-9579-cb52d41c882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70824, 2), (8524, 2), (6186, 2))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_negative_train_df.shape, pairs_negative_test_df.shape, pairs_negative_validation_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536ee83-25cf-4b98-8f07-868a5e9e5c3d",
   "metadata": {},
   "source": [
    "Sanity check zaliczony"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91388c-9532-46a2-b987-c7b7aee527f6",
   "metadata": {},
   "source": [
    "## Zadanie 4\n",
    "\n",
    "Train a text classifier using the Transformers library that distinguishes between the positive and the negative pairs. To make the process manageable use models of size base and a runtime providing GPU/TPU acceleration. Consult the discussions related to fine-tuning Transformer models to select sensible set of parameters. You can also run several trainings with different hyper-parameters, if you have access to large computing resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4132f0a-36bb-4133-b116-6fcbe192ff6c",
   "metadata": {},
   "source": [
    "Dorzucam do zebranych par etykiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47c3546f-9b59-4aca-8b24-34d1f0d36e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_count = len(pairs_positive_train_df.columns)\n",
    "pairs_positive_test_df.insert(column_count, 'label', 1)\n",
    "pairs_positive_train_df.insert(column_count, 'label', 1)\n",
    "pairs_positive_validation_df.insert(column_count, 'label', 1)\n",
    "pairs_negative_test_df.insert(column_count, 'label', 0)\n",
    "pairs_negative_train_df.insert(column_count, 'label', 0)\n",
    "pairs_negative_validation_df.insert(column_count, 'label', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc394e28-efab-425a-9e67-1e32ddc7d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "herbert_model_name = 'allegro/herbert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee311a-9924-46f9-abe3-0740a6a16d15",
   "metadata": {},
   "source": [
    "Robię tak jak w zalinkowanym w treści zadania [notebooku](https://github.com/apohllo/sztuczna-inteligencja/blob/master/lab5/lab_5.ipynb)\n",
    "\n",
    "Łączymy wszystkie pary w jeden tekst z wyrażeniami: `Pytanie:` & `Odpowiedź:`, robię z tego `ds.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eab5602-4325-4405-941c-74dc786b8f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_train_df = pd.concat([pairs_positive_train_df, pairs_negative_train_df], ignore_index=True)\n",
    "pairs_test_df = pd.concat([pairs_positive_test_df, pairs_negative_test_df], ignore_index=True)\n",
    "pairs_validation_df = pd.concat([pairs_positive_validation_df, pairs_negative_validation_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55af10b0-38a4-4e60-840f-ed8888683952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84990, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8c3eb21-7865-4c51-a718-66aa9776878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "      <td>Wytyczne IRS dotyczące tematu. Ogólnie rzecz b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Co jest uważane za wydatek służbowy w podróży ...   \n",
       "\n",
       "                                              answer  label  \n",
       "0  Wytyczne IRS dotyczące tematu. Ogólnie rzecz b...      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "579d91b6-9ead-4327-9c33-990ea0c03c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 84990\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10230\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 7424\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_transformers_dataset(df: pd.DataFrame) -> ds.Dataset:\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for ind, row in df.iterrows():\n",
    "        query = row['query']\n",
    "        answer = row['answer']\n",
    "        label = row['label']\n",
    "        texts.append(f'Pytanie: {query} Odpowiedź: {answer}')\n",
    "        labels.append(label)\n",
    "    return ds.Dataset.from_dict({\n",
    "        'text': texts,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "\n",
    "train_dataset = convert_to_transformers_dataset(pairs_train_df)\n",
    "test_dataset = convert_to_transformers_dataset(pairs_test_df)\n",
    "validation_dataset = convert_to_transformers_dataset(pairs_validation_df)\n",
    "\n",
    "datasets = ds.DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset,\n",
    "    \"validation\": validation_dataset\n",
    "})\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93b34e2c-eeee-4007-8ee1-3a54db490e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84990/84990 [00:00<00:00, 817178.97 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10230/10230 [00:00<00:00, 799473.26 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7424/7424 [00:00<00:00, 754726.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.save_to_disk(\"./dumped-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f07214d0-bbc0-459c-8277-616181e67e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "pl_tokenizer = AutoTokenizer.from_pretrained(herbert_model_name)\n",
    "\n",
    "def tokenize_fn(sample):\n",
    "    return pl_tokenizer(sample['text'], padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cbe59fb-384a-473e-98f8-1f5ed141c28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84990/84990 [00:14<00:00, 5821.72 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10230/10230 [00:01<00:00, 5797.95 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7424/7424 [00:01<00:00, 5780.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 84990\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_fn, batched=True)\n",
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0784939c-3031-4429-afd9-778c920c0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(herbert_model_name, num_labels=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f605551b-e2db-44af-8be7-bdfae1d8cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"./model/\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-05,\n",
    "    num_train_epochs=1,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88a9e200-7f17-4f70-96f0-7284b536398f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e14549e-3bca-4022-b931-b17b0d7f9039",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a525343-2299-444c-8eba-27a33f999152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_datasets['train'].shuffle(seed=84),\n",
    "    eval_dataset=tokenized_datasets['test'].shuffle(seed=84),\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa3026f4-34b2-41bf-8d2e-87f01c8d25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994de1f-77cb-432c-9a3e-eb51a5219e83",
   "metadata": {},
   "source": [
    "^ Sypnęło brakiem RAMU, więc dalsza część rozwiązania będzie w collabie.\n",
    "\n",
    "Jako osobny plik PDF załączam wyniki z collaba -- niestety nie udało mi się wytrenować modelu -- przyczyn mogę się tylko domyślać: być może chodzi o to niezbalansowanie zbioru. Czytałem podesłane artykuły, m.in. o `focal_loss` i dodawaniu wag do labelek, co ma pomóc modelowi poradzić sobie z tak niezbalansowanym zbiorem, ale nie widziałem w API transformers bezpośredniej możliwości zastosowania tego, a moja znajomosć TF / PyTorcha jest **skromna** ;D No nic, gdzieś w tygodniu się od kogoś dowiem jak to trzeba było zrobić. \n",
    "\n",
    "\n",
    "**Przejadę laby do końca, korzystając po prostu z niewytrenowanego modelu**\n",
    "\n",
    "\n",
    "Biorę po 10 najlepszych (wg FTSa) wyników dla danego zapytania, dla każdego z tych wyników, buduję query, tokenizuję je i wrzucam do modelu i popatrzę co przewidział niewytrenowany model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46e3a23d-d256-446b-9304-e33cfe2c5010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 7424\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_validation_ds = tokenized_datasets['validation']\n",
    "tokenized_validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7339b99-7f08-420e-b600-a4e74f026584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232/232 [04:09<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(tokenized_validation_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model_predictions = []\n",
    "actual_labels = []\n",
    "for batch in tqdm(dataloader):\n",
    "    tokens = pl_tokenizer(batch['text'], return_tensors='pt', padding=True, truncation=True).to('mps')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probs, dim=-1)\n",
    "    model_predictions.append(prediction)\n",
    "    \n",
    "    reality = batch['label']\n",
    "    actual_labels.append(reality)\n",
    "# model(pl_tokenizer(tokenized_validation_ds['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4fd21692-7975-47b9-a96c-8dea5bade5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 232)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_predictions), len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80b9a116-477e-4cc1-acb1-26d441095c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions_tensor = torch.cat(model_predictions).to('cpu')\n",
    "actual_labels_tensor = torch.cat(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4077eb3-4183-403b-a024-12c095d25158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18036099137931033"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = model_predictions_tensor.size()[0]\n",
    "hits = torch.count_nonzero(model_predictions_tensor == actual_labels_tensor).item()\n",
    "hits / count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad489e16-79cf-4a4f-9be6-892abb909799",
   "metadata": {},
   "source": [
    "No nie jest dobrze :D (^ accuracy na zbiorze walidacyjnym). Jednak nie ciągnę tego dalej."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9260b7ee-eccc-4bca-a03f-202dfdeac77e",
   "metadata": {},
   "source": [
    "## Pytania\n",
    "\n",
    "1. Do you think simpler methods, like Bayesian bag-of-words model, would work for sentence-pair classification? Justify your answer.\n",
    "\n",
    "Pomimo tego, że nie udało mi się wytrenować tego modelu, to zakładam, że ta metoda jest sensowna i gdyby zrobić to sensownie to można dostać wyniki nadające się do zastosowania produkcyjnego. Jezeli prównam do tego podejście BOW to moja intuicja jest taka: jako że odpowiedzi na pytania często zawierają te same tokeny co same pytania, to mogłoby to zadziałać. Czy lepiej niż Transformer -- nie sądzę, czy do produkcyjnych zastosowań? Także obstawiałbym, że nie. Natomiast chętnie posłucham omówienia tego tematu.\n",
    "\n",
    "2. What hyper-parameters you have selected for the training? What resources (papers, tutorial) you have consulted to select these hyper-parameters?\n",
    "\n",
    "Czytałem podrzucone artykuły, ale trenowanie modelu mi nie wyszło, więc pomijam :D \n",
    "\n",
    "4. Think about pros and cons of the neural-network models with respect to natural language processing. Provide at least 2 pros and 2 cons.\n",
    "\n",
    "+: sieć ma możliwość \"wykrycia głębszych\" związków pomiędzy poszczególnymi tokenami w wypowiedzi, potrafi nauczyć się \"głębokiej\" reprezentacji danych i powiązań pomiedzy różnymi fragmentami wypowiedzi\n",
    "\n",
    "+: patrząc na obecny rozwój modeli językowych, GPT-4, ostatnio Gemini (Google) & Grok (Musk) zdaje się, że jest to way-to-go, szczególnie gdy takie modele potrafią osiągać lepsze wyniki w testach na \"wnioskowanie\" i wiedzę niż 90% ludzi (odnoszę się tu do Gemini i papera który wypuściło Google Deep Mind). Na razie nie mamy innej technologi, która dawałaby podobne wyniki.\n",
    "\n",
    "+: z tego labu: szerokość zagadnień do jakich możemy stosować te modele: można mieć \"ogólnie wytrenowany\" model, a następnie go \"fine-tuning'ować\" do konkretnego zastosowania -- \"flexibility\", \"transfer-learning\"\n",
    "\n",
    "\n",
    "-: koszty (czas i pieniądze) treningu dużych modeli\n",
    "\n",
    "-: ilość potrzebnych danych, do wytrenowania modelu nadającego się do zastosowań produkcyjnych\n",
    "\n",
    "-: są sytuacje gdy korzystanie z NN to stanowczny overkill (mogą wystarczyć regexy :D)\n",
    "\n",
    "-: nie do końca wiemy co się dzieje w środku tych modeli i jak one podejmują deycyzje (black boxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413412c8-0d49-4563-8eda-6910c9f68fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
